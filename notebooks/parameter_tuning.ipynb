{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Social Network Simulation\n",
    "\n",
    "This notebook explores the impact of different hyperparameters on the simulation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from src.environment.social_network_env import SocialNetworkEnv\n",
    "from src.agents.dqn_agent import DQNAgent\n",
    "from src.training.train import train_network\n",
    "from src.training.evaluation import evaluate_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define parameter ranges to test\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.0001],\n",
    "    'batch_size': [32, 64],\n",
    "    'hidden_size': [64, 128],\n",
    "    'epsilon_decay': [0.995, 0.999]\n",
    "}\n",
    "\n",
    "# Create all combinations\n",
    "param_combinations = [dict(zip(param_grid.keys(), v)) \n",
    "                     for v in product(*param_grid.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parameter Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def evaluate_parameters(params, num_episodes=200):\n",
    "    \"\"\"Evaluate a set of parameters.\"\"\"\n",
    "    # Initialize environment\n",
    "    env = SocialNetworkEnv()\n",
    "    \n",
    "    # Initialize agent with parameters\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.n\n",
    "    agent = DQNAgent(\n",
    "        state_dim,\n",
    "        action_dim,\n",
    "        learning_rate=params['learning_rate'],\n",
    "        batch_size=params['batch_size'],\n",
    "        hidden_size=params['hidden_size'],\n",
    "        epsilon_decay=params['epsilon_decay']\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate\n",
    "    training_stats = train_network(env, agent, num_episodes=num_episodes)\n",
    "    eval_metrics = evaluate_network(env, agent)\n",
    "    \n",
    "    return {\n",
    "        'params': params,\n",
    "        'final_reward': training_stats['episode_rewards'][-1],\n",
    "        'avg_reward': np.mean(training_stats['episode_rewards']),\n",
    "        'eval_metrics': eval_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate all parameter combinations\n",
    "results = []\n",
    "for params in param_combinations:\n",
    "    print(f\"Testing parameters: {params}\")\n",
    "    result = evaluate_parameters(params)\n",
    "    results.append(result)\n",
    "    \n",
    "# Sort results by average reward\n",
    "results.sort(key=lambda x: x['avg_reward'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display top performing parameters\n",
    "print(\"Top 3 Parameter Combinations:\")\n",
    "for i, result in enumerate(results[:3]):\n",
    "    print(f\"\\n{i+1}. Parameters:\")\n",
    "    for k, v in result['params'].items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(f\"  Average Reward: {result['avg_reward']:.2f}\")\n",
    "    print(f\"  Final Reward: {result['final_reward']:.2f}\")"
   ]
  }
 ]
}
